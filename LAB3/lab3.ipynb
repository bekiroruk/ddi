{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/emreokcular/turkish-song-lyrics\n",
    "df = pd.read_csv(\"turkish_song_lyrics.csv\") \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"singer\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"singer\"])[\"song\"].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.singer.value_counts().plot.bar(title=\"Sanatçıya Göre Şarkı Sayıları\",figsize=(15,8))\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarki_sozleri = df.lyrics.to_numpy()\n",
    "sarki_sozleri[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satirlar = sarki_sozleri[0].lower().split(\"\\n\")\n",
    "satirlar[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = {} # \n",
    "A1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "satir_sonu = \"<END>\"\n",
    "\n",
    "for sarki_sozu in sarki_sozleri: # sarki_sozu : tek bir sarkinin tum satirlari\n",
    "    satirlar = sarki_sozu.lower().split(\"\\n\") # satirlar : bir sarkinin satirlari\n",
    "    \n",
    "    for satir in satirlar: # bir sarkinin 1 satiri\n",
    "        # satirdaki kelimeler (kucuk harf, noktalamasiz)\n",
    "        tokens = satir.translate(str.maketrans(\"\", \"\", string.punctuation)).split()\n",
    "        token_sayisi = len(tokens) # satirdaki kelime sayisi\n",
    "        \n",
    "        for i in range(token_sayisi):\n",
    "            token = tokens[i] # token : satirdaki kelime\n",
    "            if i == 0: # ilk kelime icin;\n",
    "                # pi dict'inde bu kelime onceden gectiyse frekansini 1 arttir\n",
    "                # eger gecmediyse frekansini 1 yap\n",
    "                pi[token] = pi.get(token, 0) + 1\n",
    "            else:\n",
    "                onceki_token = tokens[i-1] # bir onceki kelimeyi al\n",
    "                if onceki_token not in A1:\n",
    "                    # bir onceki kelime A1'de yoksa ona ait bir list yarat\n",
    "                    A1[onceki_token] = [] \n",
    "\n",
    "                # A1'de oncekli kelimeye ait listeye simdiki kelimeyi ekle\n",
    "                A1[onceki_token].append(token)\n",
    "                \n",
    "                if i == (token_sayisi - 1): # satir sonuna geldiysek\n",
    "                    # satirin son kelimesi A1'de yoksa A1'de son kelime icin bir list yarat\n",
    "                    if token not in A1:\n",
    "                        A1[token] = []\n",
    "                    # satirin son kelimesinin listesine satir sonu sembolu ekle\n",
    "                    A1[token].append(satir_sonu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_sorted = sorted(pi, key=pi.get, reverse=True)\n",
    "\n",
    "for token in pi_sorted[:10]:\n",
    "    print(token, \": \", pi[token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for k in A1:\n",
    "    if i == 7:\n",
    "        break\n",
    "    print(k, \": \", A1[k][:10], \"\\n\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_total = sum(pi.values())\n",
    "pi_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in pi:\n",
    "    # pi dict'indeki frekanslari normalize ediyoruz\n",
    "    pi[token] = pi[token] / pi_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for token in pi:\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(token, pi[token])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_total = sum(pi.values())\n",
    "pi_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1'deki key, value ikililerinin formati şu an:\n",
    "\n",
    "# gelirdi :  ['<END>', '<END>', 'ayrılıksa', 'elimizden', '<END>', '<END>', 'sevişirdik', '<END>', 'her', '<END>', ...] \n",
    "\n",
    "# Bunlari dönüştüreceğimiz format:\n",
    "\n",
    "# gelirdi :  {'<END>': 0.3, 'ayrılıksa': 0.01, 'elimizden': 0.13, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in A1: # token : gelirdi\n",
    "    tokens_list = A1[token] # tokens_list : ['<END>', '<END>', 'ayrılıksa', ...]\n",
    "    num_tokens = len(tokens_list)\n",
    "    \n",
    "    tokens_dict = {}\n",
    "    for t in tokens_list: # t : '<END>'\n",
    "        tokens_dict[t] = tokens_dict.get(t, 0) + 1 # tokens_dict : { '<END>':7, ... }\n",
    "\n",
    "    for t in tokens_dict: # tokens_dict'teki butun sayilari normalize et\n",
    "        tokens_dict[t] = tokens_dict[t] / num_tokens\n",
    "    \n",
    "    A1[token] = tokens_dict # A1'deki value'ları artık list değil; dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A1[\"giderdi\"], \"\\n\")\n",
    "print(sum(A1[\"giderdi\"].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kelime_sec(d):\n",
    "    \"\"\"\n",
    "    d: {'<END>': 0.7, 'her': 0.1, 'test': 0.2} gibi bir dict'ten \n",
    "    dict'teki olasiliklara göre rastgele bir kelime seçecek.\n",
    "    '<END>'in seçilme olasiligi 0.7, 'test'in secilme olasiligi 0.2,\n",
    "    'her'in secilme olasiligi 0.1 olacak.\n",
    "    \"\"\"\n",
    "    rastgele_sayi = np.random.random() # rastgele_sayi: [0, 1)\n",
    "    esik = 0\n",
    "    for token, prob in d.items():\n",
    "        esik += prob \n",
    "        if esik >= rastgele_sayi:\n",
    "            return token\n",
    "    \n",
    "    raise Exception(\"kelime_sec fonksiyonu yanlis calisiyor!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    token = kelime_sec(pi)\n",
    "    print(token, pi[token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    token = kelime_sec(A1[\"gelirdi\"])\n",
    "    print(token, A1[\"gelirdi\"][token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soz_yaz(satir_sayisi):\n",
    "    satirlar = []\n",
    "    for i in range(satir_sayisi):\n",
    "        satir = []\n",
    "        ilk_kelime = kelime_sec(pi)\n",
    "        satir.append(ilk_kelime)\n",
    "        \n",
    "        onceki_kelime = ilk_kelime\n",
    "        while True:\n",
    "            yeni_kelime = kelime_sec(A1[onceki_kelime])\n",
    "            if yeni_kelime == satir_sonu:\n",
    "                satirlar.append(\" \".join(satir))\n",
    "                break\n",
    "            satir.append(yeni_kelime)\n",
    "            onceki_kelime = yeni_kelime\n",
    "    \n",
    "    return \"\\n\".join(satirlar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soz_yaz(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tfnew')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93a508892ad0418bbbef2f3796edd4c06527622cb95cdcc5e9525e8332085ac2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
